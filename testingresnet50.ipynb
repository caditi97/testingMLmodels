{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MTQ4z-oOu40N"
   },
   "source": [
    "# Load model from .pb file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xrSOmAtiu40Q"
   },
   "source": [
    "This code will load and return the graph.\n",
    "\n",
    "* `model_file_name`: path to a `.pb` file.\n",
    "* `node_mapping`: mapping from the name of node in the graph to a Tensorflow node in current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "8Xa-jO4Vu40R",
    "outputId": "e1281e9e-cbdb-4c14-bdd4-bee7cc13b384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/butterchicken/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/compat/compat.py:175: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.python.platform import gfile\n",
    "def load_graph(sess, model_file_name, node_mapping={}):\n",
    "    with gfile.GFile(model_file_name, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        tf.import_graph_def(graph_def, node_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NafMpZESu40Z"
   },
   "source": [
    "This code will load the top-tagging model weights.\n",
    "\n",
    "Please change the `model_file_name` to the file name of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "jn6RS4R-u40a",
    "outputId": "72c5a42b-4a6a-455b-e797-748fdbba2f6c"
   },
   "outputs": [],
   "source": [
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior() \n",
    "with tf.Session() as sess:\n",
    "    # Create a placeholder for the input\n",
    "    input_node = tf.placeholder(tf.float32, shape = [None, 224, 224, 3], name='Placeholder')\n",
    "    graph_def = load_graph(sess=sess,\n",
    "                           model_file_name='constantgraph.pb',\n",
    "                           node_mapping={'Placeholder': input_node})\n",
    "# Get the node for output\n",
    "output_node = tf.get_default_graph().get_tensor_by_name(\"import/classifier/model_1/classifier_output/Softmax:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKlJIEVeu40f"
   },
   "source": [
    "# Export to Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2IZ-m6abu40g"
   },
   "source": [
    "This code will save the graph into a logging directory so that we can inspect it with Tensorboard.\n",
    "\n",
    "* `log_dir_name`: Path to the directory that is used to store the log. You can use `tensorboard --logdir <log_dir_name>` to inspect the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5NVBC-ohu40j"
   },
   "outputs": [],
   "source": [
    "def write_to_log(log_dir_name):\n",
    "    LOGDIR='log-top-tagging-resnet50-2'\n",
    "    train_writer = tf.summary.FileWriter(log_dir_name)\n",
    "    train_writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FWarhjKHu40m"
   },
   "source": [
    "This code will save the top-tagging model to a folder.\n",
    "\n",
    "Please change the parameter to where you want to store the Tensorboad information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EjMCzZOBu40o"
   },
   "outputs": [],
   "source": [
    "write_to_log('log-top-tagging-resnet50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ZkknadOu40r"
   },
   "source": [
    "# Run an inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UmuNZlz-u40s"
   },
   "source": [
    "This code will run an inference on a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BALjH5RUu40t",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with tf.Session() as sess:\n",
    "    y = sess.run(output_node, feed_dict={input_node: np.zeros((2, 224, 224, 3))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7w2B8CxJu40v",
    "outputId": "7ffc2f94-1682-4a4b-b777-695608990e29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00170122 0.9982988 ]\n",
      " [0.00170122 0.9982988 ]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C1M4Kbx0u40z"
   },
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cj01otnmu400"
   },
   "source": [
    "Those are helper functions from [util.py](https://github.com/nhanvtran/MachineLearningNotebooks/blob/nvt/bwcustomweights-validate/project-brainwave/utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2kX4_UWQu401"
   },
   "outputs": [],
   "source": [
    "def normalize_and_rgb(images): \n",
    "    import numpy as np\n",
    "    #normalize image to 0-255 per image.\n",
    "    image_sum = 1/np.sum(np.sum(images,axis=1),axis=-1)\n",
    "    given_axis = 0\n",
    "    # Create an array which would be used to reshape 1D array, b to have \n",
    "    # singleton dimensions except for the given axis where we would put -1 \n",
    "    # signifying to use the entire length of elements along that axis  \n",
    "    dim_array = np.ones((1,images.ndim),int).ravel()\n",
    "    dim_array[given_axis] = -1\n",
    "    # Reshape b with dim_array and perform elementwise multiplication with \n",
    "    # broadcasting along the singleton dimensions for the final output\n",
    "    image_sum_reshaped = image_sum.reshape(dim_array)\n",
    "    images = images*image_sum_reshaped*255\n",
    "\n",
    "    # make it rgb by duplicating 3 channels.\n",
    "    images = np.stack([images, images, images],axis=-1)\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gukB2aDWu404"
   },
   "outputs": [],
   "source": [
    "def count_events(train_files):\n",
    "    import tables\n",
    "    n_events = 0\n",
    "    for train_file in train_files:\n",
    "        f = tables.open_file(train_file, 'r')\n",
    "        n_events += f.root.label.shape[0]\n",
    "        f.close()\n",
    "    return n_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a3spQeNOu407"
   },
   "outputs": [],
   "source": [
    "def chunks(files, chunksize, max_q_size=4, shuffle=True): \n",
    "    \"\"\"Yield successive n-sized chunks from a and b.\"\"\" \n",
    "    import tables\n",
    "    import numpy as np\n",
    "    for train_file in files: \n",
    "        f = tables.open_file(train_file, 'r') \n",
    "        nrows = f.root.label.nrows\n",
    "        for istart in range(0,nrows,max_q_size*chunksize):  \n",
    "            a = np.array(f.root.img_pt[istart:istart+max_q_size*chunksize]) # Images \n",
    "            b = np.array(f.root.label[istart:istart+max_q_size*chunksize]) # Labels \n",
    "            if shuffle: \n",
    "                c = np.c_[a.reshape(len(a), -1), b.reshape(len(b), -1)] # shuffle within queue size\n",
    "                np.random.shuffle(c)\n",
    "                test_images = c[:, :a.size//len(a)].reshape(a.shape)\n",
    "                test_labels = c[:, a.size//len(a):].reshape(b.shape)\n",
    "            else:\n",
    "                test_images = a\n",
    "                test_labels = b\n",
    "            for jstart in range(0,len(test_labels),chunksize): \n",
    "                yield normalize_and_rgb(test_images[jstart:jstart+chunksize].copy()),test_labels[jstart:jstart+chunksize].copy(), len(test_labels[jstart:jstart+chunksize].copy())  \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IQHBqp_iu40-"
   },
   "outputs": [],
   "source": [
    "def test_model(preds, in_images, test_files, chunk_size=64, shuffle=True):\n",
    "    \"\"\"Test the model\"\"\"\n",
    "    # import tensorflow as tf \n",
    "    import tensorflow.compat.v1 as tf\n",
    "    tf.disable_v2_behavior() \n",
    "    from keras import backend as K\n",
    "    from keras.objectives import binary_crossentropy \n",
    "    import numpy as np\n",
    "    from keras.metrics import categorical_accuracy\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    in_labels = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(binary_crossentropy(in_labels, preds))\n",
    "    accuracy = tf.reduce_mean(categorical_accuracy(in_labels, preds))\n",
    "    auc = tf.metrics.auc(tf.cast(in_labels, tf.bool), preds)\n",
    "   \n",
    "    n_test_events = count_events(test_files)\n",
    "    chunk_num = int(n_test_events/chunk_size)+1\n",
    "    preds_all = []\n",
    "    label_all = []\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    avg_accuracy = 0\n",
    "    avg_auc = 0\n",
    "    avg_test_loss = 0\n",
    "    is_training = tf.get_default_graph().get_tensor_by_name('import/is_training:0')\n",
    "    n_current_events = 0\n",
    "    for img_chunk, label_chunk, real_chunk_size in chunks(test_files, chunk_size, shuffle=shuffle):\n",
    "        test_loss, accuracy_result, auc_result, preds_result = sess.run([cross_entropy, accuracy, auc, preds],\n",
    "                        feed_dict={in_images: img_chunk,\n",
    "                                   in_labels: label_chunk,\n",
    "                                   K.learning_phase(): 0,\n",
    "                                   is_training: False})\n",
    "        avg_test_loss += test_loss * real_chunk_size / n_test_events\n",
    "        avg_accuracy += accuracy_result * real_chunk_size / n_test_events\n",
    "        avg_auc += auc_result[0]  * real_chunk_size / n_test_events \n",
    "        preds_all.extend(preds_result)\n",
    "        label_all.extend(label_chunk)\n",
    "        n_current_events += real_chunk_size\n",
    "    \n",
    "        # print(\"test_loss = \", \"{:.3f}\".format(avg_test_loss*n_test_events/n_current_events), end=\"\")\n",
    "        # print(\"Test Accuracy:\", \"{:.3f}\".format(avg_accuracy*n_test_events/n_current_events), \", Area under ROC curve:\", \"{:.3f}\".format(avg_auc*n_test_events/n_current_events))\n",
    "    \n",
    "    return avg_test_loss, avg_accuracy, avg_auc, np.asarray(preds_all).reshape(n_test_events,2), np.asarray(label_all).reshape(n_test_events,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "FRwNo_CO2V3h",
    "outputId": "fd3de1ba-1831-4fa8-de4f-72b932ebb992"
   },
   "outputs": [],
   "source": [
    "avg_test_loss, avg_acc, avg_auc, test_preds_t, test_labels_t = test_model(output_node, input_node, ['test_file_0.h5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7nG8KlXZu41C"
   },
   "source": [
    "This will test the model on a test file.\n",
    "\n",
    "Please change the parameter so that it uses the correct file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQznJpM7xrpO"
   },
   "outputs": [],
   "source": [
    "# Once results have been compiled, use this function to plot them.\n",
    "# It expects all the files to be there at runtime, so if they haven't yet been generated,\n",
    "# comment out the relevant lines.\n",
    "def plot_results(avg_test, avg_acc, avg_auc, test_preds_t, test_labels_t,plot_label='ROC.pdf'):\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from sklearn import metrics\n",
    "\n",
    "    # Load the labels and results into memory.\n",
    "    # test_labels_t  = np.load(results_dir + \"/t_labels.npy\")\n",
    "    # test_preds_t   = np.load(results_dir + \"/t_preds.npy\")\n",
    "    # accuracy_q     = np.load(results_dir + \"/q_accuracy.npy\")\n",
    "    # test_labels_q  = np.load(results_dir + \"/q_labels.npy\")\n",
    "    # test_preds_q   = np.load(results_dir + \"/q_preds.npy\")\n",
    "    # test_labels_ft = np.load(results_dir + \"/ft_labels.npy\")\n",
    "    # test_preds_ft  = np.load(results_dir + \"/ft_preds.npy\")\n",
    "    # test_labels_b = np.load(results_dir + \"/b_labels.npy\")\n",
    "    # test_preds_b  = np.load(results_dir + \"/b_preds.npy\")\n",
    "    # test_labels_b_ft = np.load(results_dir + \"/b_labels.npy\")\n",
    "    # test_preds_b_ft  = np.load(results_dir + \"/b_newpreds.npy\")\n",
    "\n",
    "    new_test_preds_t = np.zeros(test_preds_t.shape)\n",
    "    new_test_preds_t[:,0] = test_preds_t[:,0]/np.sum(test_preds_t,axis=1)\n",
    "    new_test_preds_t[:,1] = test_preds_t[:,1]/np.sum(test_preds_t,axis=1)\n",
    "    test_preds_t = new_test_preds_t\n",
    "\n",
    "    # new_test_preds_q = np.zeros(test_preds_q.shape)\n",
    "    # new_test_preds_q[:,0] = test_preds_q[:,0]/np.sum(test_preds_q,axis=1)\n",
    "    # new_test_preds_q[:,1] = test_preds_q[:,1]/np.sum(test_preds_q,axis=1)\n",
    "    # test_preds_q = new_test_preds_q\n",
    "\n",
    "    # new_test_preds_ft = np.zeros(test_preds_ft.shape)\n",
    "    # new_test_preds_ft[:,0] = test_preds_ft[:,0]/np.sum(test_preds_ft,axis=1)\n",
    "    # new_test_preds_ft[:,1] = test_preds_ft[:,1]/np.sum(test_preds_ft,axis=1)\n",
    "    # test_preds_ft = new_test_preds_ft\n",
    "\n",
    "    # new_test_preds_b = np.zeros(test_preds_b.shape)\n",
    "    # new_test_preds_b[:,0] = test_preds_b[:,0]/np.sum(test_preds_b,axis=1)\n",
    "    # new_test_preds_b[:,1] = test_preds_b[:,1]/np.sum(test_preds_b,axis=1)\n",
    "    # test_preds_b = new_test_preds_b\n",
    "    \n",
    "    # new_test_preds_b_ft = np.zeros(test_preds_b_ft.shape)\n",
    "    # new_test_preds_b_ft[:,0] = test_preds_b_ft[:,0]/np.sum(test_preds_b_ft,axis=1)\n",
    "    # new_test_preds_b_ft[:,1] = test_preds_b_ft[:,1]/np.sum(test_preds_b_ft,axis=1)\n",
    "    # test_preds_b_ft = new_test_preds_b_ft\n",
    "    \n",
    "    accuracy_t = metrics.accuracy_score(test_labels_t[:,0], test_preds_t[:,0]>0.5)\n",
    "    # accuracy_q = metrics.accuracy_score(test_labels_q[:,0], test_preds_q[:,0]>0.5)\n",
    "    # accuracy_ft = metrics.accuracy_score(test_labels_ft[:,0], test_preds_ft[:,0]>0.5)\n",
    "    # accuracy_b = metrics.accuracy_score(test_labels_b[:,0], test_preds_b[:,0]>0.5)\n",
    "    # accuracy_b_ft = metrics.accuracy_score(test_labels_b_ft[:,0], test_preds_b_ft[:,0]>0.5)\n",
    "\n",
    "    # Determine the ROC curve for each of the tests. \n",
    "    # [:,0] will convert the labels from one-hot to binary.\n",
    "    fpr_test_t, tpr_test_t, thresholds      = metrics.roc_curve(test_labels_t[:,0],  test_preds_t[:,0])\n",
    "    # fpr_test_q, tpr_test_q, thresholds_q    = metrics.roc_curve(test_labels_q[:,0],  test_preds_q[:,0])\n",
    "    # fpr_test_ft, tpr_test_ft, thresholds_ft    = metrics.roc_curve(test_labels_ft[:,0],  test_preds_ft[:,0])\n",
    "    # fpr_test_b, tpr_test_b, thresholds_b    = metrics.roc_curve(test_labels_b[:,0],  test_preds_b[:,0])\n",
    "    # fpr_test_b_ft, tpr_test_b_ft, thresholds_b_ft    = metrics.roc_curve(test_labels_b_ft[:,0],  test_preds_b_ft[:,0])\n",
    "    \n",
    "    # Use the data we just generated to determine the area under the ROC curve.\n",
    "    # Use the data we just generated to determine the area under the ROC curve.\n",
    "    auc_test    = metrics.auc(fpr_test_t, tpr_test_t)\n",
    "    # auc_test_q  = metrics.auc(fpr_test_q, tpr_test_q)\n",
    "    # auc_test_ft  = metrics.auc(fpr_test_ft, tpr_test_ft)\n",
    "    # auc_test_b  = metrics.auc(fpr_test_b, tpr_test_b)\n",
    "    # auc_test_b_ft  = metrics.auc(fpr_test_b_ft, tpr_test_b_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-397dfd535696>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preds_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "plot = plot_results(avg_test_loss, avg_acc, avg_auc, test_preds_t, test_labels_t)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AJ1d-mkAu41G"
   },
   "source": [
    "# Load model from .h5 file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGT5w-gAu41H"
   },
   "source": [
    "Change `file_name` to the path of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K1v2Bn72u41I"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "file_name = 'class_model_best.h5'\n",
    "new_model = keras.models.load_model(file_name)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xqgzm3Vku41L"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "testingresnet50.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
